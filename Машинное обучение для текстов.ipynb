{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ea742d",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a27451a",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b2ec5",
   "metadata": {},
   "source": [
    "## 1. Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1943e1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split,  GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1be9a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#откроем файл\n",
    "try:\n",
    "    data_text=pd.read_csv('desktop/datasets/toxic_comments.csv')\n",
    "except:\n",
    "    data_text=pd.read_csv('/datasets/toxic_comments.csv')\n",
    "\n",
    "data_text.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8be9143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "#просмотрим основную информацию о датасете\n",
    "data_text.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a1a5d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_text.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49cba10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.898321\n",
      "1    0.101679\n",
      "Name: toxic, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#как часто модель предсказывала класс «1» или «0» по Дереву решений:\n",
    "class_frequency_dtc = pd.Series(data_text['toxic']).value_counts(normalize=True)\n",
    "print(class_frequency_dtc)\n",
    "\n",
    "#на диаграмме\n",
    "sns.set_style('darkgrid')\n",
    "class_frequency_dtc.plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c8277ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#обработаем регистр\n",
    "data_text['text']=data_text['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba73b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.7 s, sys: 3.87 s, total: 35.5 s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#сделаем леммитизацию\n",
    "m = Mystem()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemm_text = \"\".join(m.lemmatize(text))\n",
    "    cleared_text = re.sub(r'[^a-zA-Z]', ' ', lemm_text) \n",
    "    return \" \".join(cleared_text.split())\n",
    "\n",
    "data_text['lemm_text'] = data_text['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe43e439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation\\nwhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d'aww! he matches this background colour i'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man, i'm really not trying to edit war. it...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nmore\\ni can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you, sir, are my hero. any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  explanation\\nwhy the edits made under my usern...      0   \n",
       "1  d'aww! he matches this background colour i'm s...      0   \n",
       "2  hey man, i'm really not trying to edit war. it...      0   \n",
       "3  \"\\nmore\\ni can't make any real suggestions on ...      0   \n",
       "4  you, sir, are my hero. any chance you remember...      0   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edits made under my userna...  \n",
       "1  d aww he matches this background colour i m se...  \n",
       "2  hey man i m really not trying to edit war it s...  \n",
       "3  more i can t make any real suggestions on impr...  \n",
       "4  you sir are my hero any chance you remember wh...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#посмотрим что получилось\n",
    "data_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38c33ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим на признаки и целевую переменную\n",
    "features = data_text['lemm_text']\n",
    "target = data_text['toxic']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1187081f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/juliana/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#стоп-слова и векторизация текста\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "\n",
    "tf_idf = TfidfVectorizer(stop_words=stopwords) \n",
    "features_train = tf_idf.fit_transform(features_train)\n",
    "features_test = tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26544b77",
   "metadata": {},
   "source": [
    "<b>ВЫВОД:</b>\n",
    "В процессе изучения данных было выполнено:\n",
    "\n",
    "- тексты были очищены и лемматизированы;\n",
    "- проверен баланс классов и в результате установлено, что  имеет место значительный дисбаланс, таким образом это необходимо учесть в дальнейшем при обучении моделей. \n",
    "- выделены признаки и целевая переменная;\n",
    "- для векторизации текстов был использован TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1784a37f",
   "metadata": {},
   "source": [
    "## 2. Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae649ae",
   "metadata": {},
   "source": [
    "Будем использовать Логистическую регрессию, LightGBM и модель Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66670dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.6 s, sys: 503 ms, total: 37.1 s\n",
      "Wall time: 9.45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=LogisticRegression(class_weight='balanced',\n",
       "                                          random_state=12345,\n",
       "                                          solver='liblinear'),\n",
       "             param_grid={'C': [0.1, 1, 10]}, scoring='f1')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Логистическая регрессия с пареметром class_weight = 'balanced'\n",
    "regressor = LogisticRegression(fit_intercept=True, \n",
    "                                class_weight='balanced', \n",
    "                                random_state=12345,\n",
    "                                solver='liblinear'\n",
    "                                 )\n",
    "\n",
    "lg_param = {'C': [0.1, 1, 10]}\n",
    "\n",
    "#обучаем \n",
    "lg_model = GridSearchCV(regressor, param_grid=lg_param, scoring='f1', cv=3)\n",
    "lg_model.fit(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20e8b4c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7647395724887668\n",
      "{'C': 10}\n"
     ]
    }
   ],
   "source": [
    "print(lg_model.best_score_)\n",
    "print(lg_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352877b5",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ceef9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45min 3s, sys: 44.1 s, total: 45min 47s\n",
      "Wall time: 6min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=LGBMClassifier(class_weight='balanced',\n",
       "                                      random_state=12345),\n",
       "             param_grid={'learning_rate': [0.2], 'max_depth': [-1],\n",
       "                         'n_estimators': [100, 200, 1000]},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "regressor_lgbm = LGBMClassifier(class_weight='balanced',random_state = 12345)\n",
    "\n",
    "lgbm_param= {'max_depth' : [-1],\n",
    "                'learning_rate' : [0.2],\n",
    "                'n_estimators' : [100,200,1000]\n",
    "               }\n",
    "\n",
    "lgbm_model = GridSearchCV(estimator=regressor_lgbm, \n",
    "                          param_grid=lgbm_param, \n",
    "                          scoring = 'f1', \n",
    "                          cv=3)\n",
    "\n",
    "lgbm_model.fit(features_train, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e07f7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7607782928393162\n",
      "{'learning_rate': 0.2, 'max_depth': -1, 'n_estimators': 1000}\n"
     ]
    }
   ],
   "source": [
    "print(lgbm_model.best_score_)\n",
    "print(lgbm_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8ad366",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d2415c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17 s, sys: 2.35 s, total: 19.3 s\n",
      "Wall time: 30.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=RandomForestClassifier(class_weight='balanced',\n",
       "                                              n_jobs=-1, random_state=12345),\n",
       "             param_grid={'max_depth': range(4, 8, 2),\n",
       "                         'n_estimators': range(20, 40, 5)},\n",
       "             scoring='f1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "forest_regressor = RandomForestClassifier(class_weight='balanced',random_state = 12345, n_jobs=-1 )\n",
    "\n",
    "forest_param = {'n_estimators': range(20, 40, 5),\n",
    "                     'max_depth': range(4, 8, 2),\n",
    "                     }\n",
    "\n",
    "forest_model = GridSearchCV(estimator=forest_regressor, \n",
    "                            param_grid=forest_param, \n",
    "                            scoring='f1', \n",
    "                            cv=3)\n",
    "\n",
    "forest_model.fit(features_train, target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b9a936b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3025906364532773\n",
      "{'max_depth': 6, 'n_estimators': 35}\n"
     ]
    }
   ],
   "source": [
    "print(forest_model.best_score_)\n",
    "print(forest_model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e77edd",
   "metadata": {},
   "source": [
    "## 3.  ВЫВОДЫ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6f5427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#лучшие модели\n",
    "best_forest=forest_model.best_estimator_\n",
    "best_lgbm=lgbm_model.best_estimator_\n",
    "best_linear=lg_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfdac88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest 0.3329835940480732\n",
      "LightGBM 0.7739387956564658\n",
      "Logistic Regression 0.771059312254789\n"
     ]
    }
   ],
   "source": [
    "#предсказываем по лучшим моделям\n",
    "forest_predict = best_forest.predict(features_test)\n",
    "lgbm_predict = best_lgbm.predict(features_test)\n",
    "linear_predict = best_linear.predict(features_test)\n",
    "\n",
    "#финальный f1 на тесте\n",
    "print('Random Forest',f1_score(target_test, forest_predict))\n",
    "print('LightGBM',f1_score(target_test, lgbm_predict))\n",
    "print('Logistic Regression',f1_score(target_test, linear_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3714d972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Модель</th>\n",
       "      <th>f1-мера на тесте</th>\n",
       "      <th>f1-мера на трейне</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Логистическая регрессия</td>\n",
       "      <td>0.771059</td>\n",
       "      <td>0.764740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.773939</td>\n",
       "      <td>0.760778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Случайный лес</td>\n",
       "      <td>0.332984</td>\n",
       "      <td>0.302591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Модель  f1-мера на тесте  f1-мера на трейне\n",
       "0  Логистическая регрессия          0.771059           0.764740\n",
       "1                 LightGBM          0.773939           0.760778\n",
       "2            Случайный лес          0.332984           0.302591"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#сводная таблица с результатами \n",
    "columns = ['Модель', 'f1-мера на тесте','f1-мера на трейне']\n",
    "\n",
    "linear_regression_model = ['Логистическая регрессия', f1_score(target_test, linear_predict),lg_model.best_score_]\n",
    "lightGBM_model = ['LightGBM', f1_score(target_test, lgbm_predict),lgbm_model.best_score_]\n",
    "random_forest_model = ['Случайный лес', f1_score(target_test, forest_predict),forest_model.best_score_]\n",
    "\n",
    "table = pd.DataFrame([linear_regression_model, lightGBM_model, random_forest_model], columns = columns)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac343d99",
   "metadata": {},
   "source": [
    "<b>ВЫВОД:</b>\n",
    "1. Изучены и подготовлены данные, в том числе:\n",
    "    \n",
    "    - тексты были очищены и лемматизированы;\n",
    "    - проверен баланс классов и в результате установлено, что имеет место значительный дисбаланс, таким образом это учтено при дальнейшем при обучении моделей внесением class_weight='balanced'.\n",
    "    - выделены признаки и целевая переменная;\n",
    "    - для векторизации текстов  использован TfidfVectorizer()\n",
    "    \n",
    "2. Обучены три модели:  Logistic Regression, LGBMClassifier и Random Forest Classifier. Получены лучшие параметры на тесте и трейне, данные сведены в общую таблицу.\n",
    "3. Установлено, что лучшая модель - LGBMClassifier, худшая - Random Forest, однако LGBMClassifier обучалась значительно дольше.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d406b80b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
